import os
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CrossEncoderReranker
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from transformers import AutoModelForSequenceClassification, AutoTokenizer

from .tools import get_info_from_db


def get_vector_db():
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    try:
        db = FAISS.load_local(
            os.getcwd() + "/table_info_db",
            embeddings,
            allow_dangerous_deserialization=True,
        )
    except:
        documents = get_info_from_db()
        db = FAISS.from_documents(documents, embeddings)
        db.save_local(os.getcwd() + "/table_info_db")
        print("table_info_db not found")
    return db


def load_reranker_model():
    """í•œêµ­ì–´ reranker ëª¨ë¸ì„ ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    local_model_path = os.path.join(os.getcwd(), "ko_reranker_local")

    # ë¡œì»¬ì— ì €ìž¥ëœ ëª¨ë¸ì´ ìžˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ í›„ ì €ìž¥
    if os.path.exists(local_model_path) and os.path.isdir(local_model_path):
        print("ðŸ”„ ko-reranker ëª¨ë¸ ë¡œì»¬ì—ì„œ ë¡œë“œ ì¤‘...")
    else:
        print("â¬‡ï¸ ko-reranker ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ìž¥ ì¤‘...")
        model = AutoModelForSequenceClassification.from_pretrained(
            "Dongjin-kr/ko-reranker"
        )
        tokenizer = AutoTokenizer.from_pretrained("Dongjin-kr/ko-reranker")
        model.save_pretrained(local_model_path)
        tokenizer.save_pretrained(local_model_path)

    return HuggingFaceCrossEncoder(model_name=local_model_path)


def get_retriever(use_rerank=False):
    """ê²€ìƒ‰ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. use_rerankê°€ Trueì´ë©´ rerankingì„ ì ìš©í•©ë‹ˆë‹¤."""
    db = get_vector_db()
    retriever = db.as_retriever(search_kwargs={"k": 10})

    if use_rerank:
        model = load_reranker_model()
        compressor = CrossEncoderReranker(model=model, top_n=3)
        return ContextualCompressionRetriever(
            base_compressor=compressor, base_retriever=retriever
        )
    else:
        return retriever


def search_tables(query, use_rerank=False):
    """ì¿¼ë¦¬ì— ë§žëŠ” í…Œì´ë¸” ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    if use_rerank:
        retriever = get_retriever(use_rerank=True)
        doc_res = retriever.invoke(query)
    else:
        db = get_vector_db()
        doc_res = db.similarity_search(query, k=10)

    # ê²°ê³¼ë¥¼ ì‚¬ì „ í˜•íƒœë¡œ ë³€í™˜
    documents_dict = {}
    for doc in doc_res:
        lines = doc.page_content.split("\n")

        # í…Œì´ë¸”ëª… ë° ì„¤ëª… ì¶”ì¶œ
        table_name, table_desc = lines[0].split(": ", 1)

        # ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ
        columns = {}
        if len(lines) > 2 and lines[1].strip() == "Columns:":
            for line in lines[2:]:
                if ": " in line:
                    col_name, col_desc = line.split(": ", 1)
                    columns[col_name.strip()] = col_desc.strip()

        # ë”•ì…”ë„ˆë¦¬ ì €ìž¥
        documents_dict[table_name] = {
            "table_description": table_desc.strip(),
            **columns,  # ì»¬ëŸ¼ ì •ë³´ ì¶”ê°€
        }

    return documents_dict
